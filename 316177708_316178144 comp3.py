# -*- coding: utf-8 -*-
"""Competition_3Latest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LgaSWo_vj6UrdI4Rf_TLte9JmGjdwWJ8

Amit Avigdor - 316178144<br>
Barak Bonker - 316177708<br>

# Importing libraries
"""

import os 
import cv2
import numpy as np
from PIL import Image
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.utils import np_utils, image_dataset_from_directory, to_categorical
from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Dropout 
from keras.layers import RandomRotation, RandomZoom, Rescaling, Flatten, RandomFlip
from google.colab import drive,files

"""# Setting Working Directory"""

# Commented out IPython magic to ensure Python compatibility.
drive.mount('/content/drive',force_remount=True)
# %cd '/content/drive/My Drive/Deep Learning/Comp3'

"""# Auxiliary functions"""

def load_data(dir):
  return [os.path.join(dir,f) for f in os.listdir(os.path.join(dir))]

def drop_no_or_cor_image_data(data,dir):
  for i in data.index:
    if not os.path.exists(dir+"/"+str(data["id"][i])+".jpg"):
      print("droped non found image", str(data["id"][i]))
      data.drop(i, axis=0, inplace=True)
    else: 
      try:
        Image.open(dir+"/"+str(data["id"][i])+".jpg").verify()
      except:
        print("droped corupted image", str(data["id"][i]))
        data.drop(i, axis=0, inplace=True)

def change_label_to_catagorical(data):
  labels = data['label'].values
  one_hot_labels = to_categorical(labels)
  rows = [{'label': arr} for arr in one_hot_labels]
  data['label'] = [d['label'] for d in rows]

def to_png(data,dir):
  converted_dir = dir+'/converted'
  if not os.path.exists(converted_dir):
    os.makedirs(converted_dir)  
  for i in data.index:
    if not os.path.exists(converted_dir+"/"+str(data["id"][i])+".png"):
      tif_path = os.path.join(dir, str(data["id"][i])+".jpg")
      img = Image.open(tif_path).convert('RGB')
      png_path = os.path.join(converted_dir, str(data["id"][i]) +'.png')
      img.save(png_path)
  return converted_dir

def image_preprocess(data,dir,format):
  data["data"] = ""
  for i in data.index:
      image = cv2.imread(dir+"/"+str(data["id"][i])+format)
      img_normalized = cv2.normalize(image, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
      data.at[i,"data"] = cv2.resize(img_normalized, (128,128), interpolation = cv2.INTER_AREA)

def image_preprocess_with_noise(data,dir,format):

  data["data"] = ""

  for i in data.index:
      image = cv2.imread(dir+"/"+str(data["id"][i])+format)
      copy = image.copy()
      img_normalized = cv2.normalize(image, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
      data.at[i,"data"] = cv2.resize(img_normalized, (128,128), interpolation = cv2.INTER_AREA)

      #add noise
      noise = np.random.normal(0, 50, copy.shape)
      noisy_img = image + noise
      noisy_img = np.clip(noisy_img, 0, 255).astype('uint8')
      img_normalized = cv2.normalize(noisy_img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
      
      resized_image = cv2.resize(img_normalized, (128,128), interpolation = cv2.INTER_AREA)
      new_row = {'id': str(data["id"][i])+"_noised", 'label': str(data["label"][i]), 'data': resized_image}
      next_index = max(data.index, default=-1) + 1
      data.loc[next_index] = new_row

      #add rotate
      angle = np.random.uniform(-30, 30)
      rows, cols, _ = copy.shape
      M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)
      rotated_img = cv2.warpAffine(copy, M, (cols, rows))

      img_normalized = cv2.normalize(rotated_img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
      
      resized_image = cv2.resize(img_normalized, (128,128), interpolation = cv2.INTER_AREA)
      new_row = {'id': str(data["id"][i])+"_rotated", 'label': str(data["label"][i]), 'data': resized_image}
      next_index = max(data.index, default=-1) + 1
      data.loc[next_index] = new_row
      #data.loc[len(data)] = [str(data["id"][i])+"_noised", str(data["label"][i]), resized_image]

"""# Train set"""

train_dir="/content/drive/My Drive/Deep Learning/Comp3/train_data"
train_data_class = pd.read_csv("train_labels_ex3.csv")

print('Amount of train data: ')
print(len(load_data(train_dir)))

train_data_class

drop_no_or_cor_image_data(train_data_class,train_dir)
train_data_class

train_dir = to_png(train_data_class,train_dir)

"""## keras's"""

#loading train png data with keras
#image_format = ".jpg"
#image_preprocess(train_data_class, train_png_dir, image_format)
train_data_class.sort_values(by=['id'])
train_keras_data, val_keras_data = image_dataset_from_directory(
                      train_dir,
                      labels=train_data_class["label"].tolist(),
                      label_mode="categorical",
                      validation_split=0.2,
                      subset="both",
                      seed=1337,
                      batch_size=32,
                      image_size=(128, 128),
                      interpolation='nearest',
                      shuffle=True
                      )

train_keras_data

#data augmentation train png data with keras
data_augmentation = Sequential(
  [
    #RandomFlip("horizontal"),
    #RandomRotation(0.1),
    #RandomZoom(0.1),
    Rescaling(1./255)
  ]
)

train_keras_data = train_keras_data.map(lambda x, y: (data_augmentation(x, training=True), y))

"""## ours"""

image_format = ".png"
train_dir="/content/drive/My Drive/Deep Learning/Comp3/train_data/converted"
#image_preprocess(train_data_class,train_dir,image_format)
image_preprocess_with_noise(train_data_class, train_dir, image_format)
train_data_class

train_data_class.shape

shape = train_data_class['data'][0].shape
shape

change_label_to_catagorical(train_data_class)
train_data_class

X = np.asarray(train_data_class["data"].tolist()).astype('float32')
y = np.asarray(train_data_class["label"].tolist()).astype('float32')
#y_train = y_train.reshape(-1, 1)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Building the model"""

from tensorflow.keras.applications import VGG16

# Load the pre-trained VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))

# Freeze the pre-trained layers
for layer in vgg16.layers:
    layer.trainable = False

# Create a new model
model = Sequential()

# Add the VGG16 model as the first layer
model.add(vgg16)

# Add remaining layers
model.add(Conv2D(64, 3, padding="same", activation="relu"))
model.add(Conv2D(64, 3, padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(128, 3, padding="same", activation="relu"))
model.add(Conv2D(128, 3, padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=2))

model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=['accuracy'])
model.summary()

"""# Training the model

## keras
"""

#training with kares
model.fit(train_keras_data, epochs=30, batch_size=32, validation_data=val_keras_data)

"""## ours"""

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=5) 

model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[early_stop])

"""# Evaluating the model

## keras
"""

#keras evaluate
score = model.evaluate(val_keras_data)
print('val loss:', score[0])
print('val accuracy:', score[1])

"""## ours"""

score = model.evaluate(X_val, y_val)
print('val loss:', score[0])
print('val accuracy:', score[1])

"""# Test set"""

test_dir="/content/drive/My Drive/Deep Learning/Comp3/test_data"
test_data_class = pd.read_csv("sample_submission_ex3.csv")

print(len(load_data(test_dir)))
test_data_class

drop_no_or_cor_image_data(test_data_class,test_dir)
test_data_class

test_png_dir = to_png(test_data_class, test_dir)

"""## keras's"""

test_data_class.sort_values(by=['id'])
test_keras_data = image_dataset_from_directory(
                      test_png_dir,
                      labels=None,
                      label_mode="categorical",
                      seed=1337,
                      batch_size=32,
                      image_size=(128, 128),
                      interpolation='nearest',
                      )

test_keras_data

norm_and_flat = Sequential(
  [
    Rescaling(1./255),
  ]
)

test_keras_data = test_keras_data.map(lambda x: (norm_and_flat(x,)))

"""## ours"""

image_preprocess(test_data_class,test_png_dir,".png")
test_data_class

X_test = np.array(test_data_class["data"].tolist()).astype('float32')

"""# Prediction

## keras's
"""

y_pred = model.predict(test_keras_data)
y_pred

"""## ours"""

y_pred = model.predict(X_test)
y_pred

"""# Prediction to class"""

cata_pred = [np.argmax(x) for x in y_pred]
cata_pred

values, counts = np.unique(cata_pred, return_counts=True)
print(counts)

test_data_class["label"] = cata_pred

test_data_class.drop("data", axis=1, inplace=True)
test_data_class

from google.colab import files
test_data_class.to_csv('submission.csv', encoding = 'utf-8-sig', index=False)